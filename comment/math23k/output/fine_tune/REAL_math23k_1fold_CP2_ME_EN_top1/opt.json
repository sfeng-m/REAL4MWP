{
  "Fold": 1,
  "add_copynet": true,
  "add_memory_module": true,
  "add_num_equ_ids": true,
  "always_truncate_tail": true,
  "amp": false,
  "attention_probs_dropout_prob": 0.1,
  "beam_size": 1,
  "bert_model": "bert-base-chinese",
  "config_path": null,
  "dataset": "math23k",
  "do_eval": false,
  "do_l2r_training": false,
  "do_lower_case": false,
  "do_train": false,
  "easy_to_hard": false,
  "eval_batch_size": 12,
  "ffn_type": 0,
  "finetune_decay": false,
  "forbid_duplicate_ngrams": false,
  "forbid_ignore_word": ".",
  "fp16": false,
  "fp32_embedding": false,
  "from_scratch": false,
  "gradient_accumulation_steps": 1,
  "has_sentence_oracle": false,
  "hidden_dropout_prob": 0.1,
  "is_debug": false,
  "is_delete_early_model": false,
  "is_equ_norm": true,
  "is_single_char": false,
  "is_train": true,
  "label_smoothing": 0.1,
  "learning_rate": 2e-05,
  "length_penalty": 0,
  "local_rank": -1,
  "log_dir": "./comment/math23k/output/fine_tune/bert_log",
  "loss_scale": 0,
  "mask_prob": 0.15,
  "mask_prob_eos": 0,
  "mask_source_words": false,
  "mask_whole_word": true,
  "max_analogy_len": 512,
  "max_len_a": 192,
  "max_len_b": 64,
  "max_position_embeddings": 512,
  "max_pred": 64,
  "max_seq_length": 256,
  "max_tgt_length": 64,
  "memory_train_file": "./preprocess/sim_result/sim_question_by_w2v_train_math23k_equNorm_1fold_top5.pkl",
  "memory_valid_file": "./preprocess/sim_result/sim_question_by_w2v_valid_math23k_equNorm_1fold_top5.pkl",
  "min_len": null,
  "mode": "s2s",
  "model_recover_path": "./comment/math23k/output/fine_tune/REAL_math23k_1fold_CP2_ME_EN_top1/model.epoch.bin",
  "need_score_traces": true,
  "new_pos_ids": false,
  "new_segment_ids": false,
  "ngram_size": 3,
  "no_cuda": false,
  "not_predict_token": null,
  "num_equ_size": 3,
  "num_qkv": 0,
  "num_train_epochs": 80.0,
  "num_workers": 0,
  "optim_recover_path": null,
  "output_dir": "./comment/math23k/output/fine_tune/REAL_math23k_1fold_CP2_ME_EN_top1",
  "pos_shift": true,
  "relax_projection": false,
  "s2s_add_segment": false,
  "s2s_share_segment": false,
  "s2s_special_token": false,
  "save_every_epoch": false,
  "seed": 42,
  "seg_emb": false,
  "skipgram_prb": 0.0,
  "skipgram_size": 1,
  "split": "test",
  "start_lr_decay_epoch": 40,
  "subset": 0,
  "tokenized_input": false,
  "topk": 1,
  "train_batch_size": 6,
  "trunc_seg": "a",
  "used_bertAdam": false,
  "warmup_proportion": 0.1,
  "weight_decay": 0.01
}